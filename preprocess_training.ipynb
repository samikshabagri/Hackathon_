{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f44754a1-ee4b-4340-a852-8b85ee1d3db6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# === Step 2: Load dataset ===\n",
    "df = pd.read_csv(\"csic_database.csv\")\n",
    "\n",
    "# === Step 3: Quick check ===\n",
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38ca6af3-c246-4dd3-8909-c475a1289e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed duplicates: 35457\n",
      "Dropped columns (mostly-missing or constant): ['User-Agent', 'Cache-Control', 'Accept-charset', 'language', 'Pragma', 'Accept-encoding']\n",
      "Final shape after cleaning: (25608, 12)\n",
      "\n",
      "Top 10 columns by missingness after cleaning:\n",
      "lenght            0.526789\n",
      "Accept            0.010348\n",
      "Unnamed: 0        0.000000\n",
      "Method            0.000000\n",
      "host              0.000000\n",
      "cookie            0.000000\n",
      "content-type      0.000000\n",
      "connection        0.000000\n",
      "content           0.000000\n",
      "classification    0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = (\"csic_database.csv\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# 1) Standardize column names (strip spaces)\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "# 2) Create a proper numeric content-length column from the 'lenght' header (keep original)\n",
    "if \"lenght\" in df.columns:\n",
    "    df[\"content_length_header\"] = (\n",
    "        df[\"lenght\"].astype(str).str.extract(r\"(\\d+)\").astype(float)\n",
    "    )\n",
    "\n",
    "# 3) Ensure key columns exist\n",
    "for c in [\"Method\", \"connection\", \"content-type\", \"URL\", \"content\", \"classification\"]:\n",
    "    if c not in df.columns:\n",
    "        df[c] = np.nan\n",
    "\n",
    "# 4) Trim whitespace in categorical-like columns\n",
    "for c in [\"Method\", \"connection\", \"content-type\", \"URL\"]:\n",
    "    df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "# 5) Handle missing values\n",
    "#   - Text fields: empty string\n",
    "for c in [\"URL\", \"content\"]:\n",
    "    df[c] = df[c].fillna(\"\")\n",
    "\n",
    "#   - Categoricals: 'missing'\n",
    "for c in [\"Method\", \"connection\", \"content-type\"]:\n",
    "    df[c] = df[c].fillna(\"missing\").replace({\"\": \"missing\"})\n",
    "\n",
    "#   - Numeric fields: 0 (only for the ones we know should be numeric)\n",
    "numeric_candidates = [\"content_length_header\"]\n",
    "numeric_cols = [c for c in numeric_candidates if c in df.columns]\n",
    "for c in numeric_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# 6) Remove exact duplicate requests (based on Method+URL+content)\n",
    "before = len(df)\n",
    "df = df.drop_duplicates(subset=[\"Method\", \"URL\", \"content\"])\n",
    "removed_dupes = before - len(df)\n",
    "\n",
    "# 7) Drop columns that are >95% missing OR constant (except target)\n",
    "missing_ratio = df.isna().mean()\n",
    "const_cols = [c for c in df.columns if df[c].nunique(dropna=False) <= 1]\n",
    "to_drop = set(missing_ratio[missing_ratio > 0.95].index.tolist() + const_cols)\n",
    "to_drop.discard(\"classification\")  # never drop target if present\n",
    "df.drop(columns=list(to_drop), inplace=True, errors=\"ignore\")\n",
    "\n",
    "# 8) Replace any inf/-inf with NaN then fill (safety)\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.fillna({\"URL\": \"\", \"content\": \"\"}, inplace=True)  # ensure key text fields not NaN\n",
    "\n",
    "# 9) Final report\n",
    "print(\"Removed duplicates:\", removed_dupes)\n",
    "print(\"Dropped columns (mostly-missing or constant):\", list(to_drop))\n",
    "print(\"Final shape after cleaning:\", df.shape)\n",
    "print(\"\\nTop 10 columns by missingness after cleaning:\")\n",
    "print(df.isna().mean().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2122fbb-b5ff-48e0-8fae-2dfceffaf56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature engineering complete and saved as FeatureSet.csv\n",
      "  - TF-IDF features: 3000\n",
      "  - One-hot categorical features: 7\n",
      "  - Numeric + heuristic features: 78\n",
      "  - TOTAL features: 3085\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# === Step 1: Load dataset ===\n",
    "df = pd.read_csv(\"csic_database.csv\")\n",
    "\n",
    "# === Step 2: Basic numeric and combined text features ===\n",
    "df[\"url_len\"] = df[\"URL\"].fillna(\"\").str.len()\n",
    "df[\"content_len\"] = df[\"content\"].fillna(\"\").str.len()\n",
    "df[\"num_params\"] = df[\"URL\"].fillna(\"\").str.count(r\"[?&]\")\n",
    "df[\"cookie_len\"] = df[\"cookie\"].fillna(\"\").astype(str).str.len()\n",
    "df[\"text\"] = (df[\"URL\"].fillna(\"\") + \" \" + df[\"content\"].fillna(\"\")).str.lower()\n",
    "\n",
    "# === Step 3: Suspicious character counts ===\n",
    "bad_chars = [\"'\", '\"', \"<\", \">\", \";\", \"%\", \"-\", \"/\", \"\\\\\", \"=\", \"|\", \"&\"]\n",
    "for ch in bad_chars:\n",
    "    df[f\"count_{ch}\"] = df[\"text\"].str.count(re.escape(ch))\n",
    "\n",
    "# === Step 4: OWASP keyword flags ===\n",
    "attack_keywords = {\n",
    "    \"has_select\": r\"\\bselect\\b\", \"has_union\": r\"\\bunion\\b\", \"has_drop\": r\"\\bdrop\\b\",\n",
    "    \"has_insert\": r\"\\binsert\\b\", \"has_update\": r\"\\bupdate\\b\", \"has_delete\": r\"\\bdelete\\b\",\n",
    "    \"has_concat\": r\"\\bconcat\\b\", \"has_information_schema\": r\"\\binformation_schema\\b\",\n",
    "    \"has_sleep\": r\"\\bsleep\\s*\\(\", \"has_benchmark\": r\"\\bbenchmark\\s*\\(\",\n",
    "    \"has_load_file\": r\"\\bload_file\\b\", \"has_into_outfile\": r\"\\binto\\s+outfile\\b\",\n",
    "    \"has_substr\": r\"\\bsubstr\\b\", \"has_ascii\": r\"\\bascii\\b\", \"has_hex\": r\"\\bhex\\b\",\n",
    "    \"has_char_func\": r\"\\bchar\\s*\\(\", \"has_or_1_eq_1\": r\"\\bor\\s+1=1\\b\",\n",
    "    \"has_and_1_eq_1\": r\"\\band\\s+1=1\\b\", \"has_comment_sql\": r\"--|;--|/\\*.*\\*/\",\n",
    "\n",
    "    # XSS\n",
    "    \"has_script_tag\": r\"<\\s*script\", \"has_iframe_tag\": r\"<\\s*iframe\",\n",
    "    \"has_img_tag\": r\"<\\s*img\", \"has_svg_tag\": r\"<\\s*svg\", \"has_object_tag\": r\"<\\s*object\",\n",
    "    \"has_embed_tag\": r\"<\\s*embed\", \"has_link_tag\": r\"<\\s*link\", \"has_meta_tag\": r\"<\\s*meta\",\n",
    "    \"has_style_tag\": r\"<\\s*style\", \"has_alert\": r\"alert\\s*\\(\", \"has_onerror\": r\"onerror=\",\n",
    "    \"has_onload\": r\"onload=\", \"has_onclick\": r\"onclick=\", \"has_onfocus\": r\"onfocus=\",\n",
    "    \"has_onmouseover\": r\"onmouseover=\", \"has_document_cookie\": r\"document\\.cookie\",\n",
    "    \"has_document_write\": r\"document\\.write\", \"has_window_location\": r\"window\\.location\",\n",
    "    \"has_javascript_proto\": r\"javascript:\",\n",
    "\n",
    "    # Command Injection / Path Traversal\n",
    "    \"has_dotdot\": r\"\\.\\./\", \"has_passwd\": r\"/etc/passwd\", \"has_whoami\": r\"\\bwhoami\\b\",\n",
    "    \"has_wget\": r\"\\bwget\\b\", \"has_curl\": r\"\\bcurl\\b\", \"has_python\": r\"\\bpython\\b\",\n",
    "    \"has_perl\": r\"\\bperl\\b\", \"has_bash\": r\"\\bbash\\b\", \"has_exec\": r\"\\bexec\\b\",\n",
    "    \"has_system\": r\"\\bsystem\\s*\\(\", \"has_pipe_or\": r\"\\|\\|\", \"has_pipe_and\": r\"\\&\\&\",\n",
    "\n",
    "    # File Inclusion\n",
    "    \"has_php\": r\"\\.php\", \"has_asp\": r\"\\.asp\", \"has_jsp\": r\"\\.jsp\", \"has_exe\": r\"\\.exe\",\n",
    "    \"has_sh\": r\"\\.sh\", \"has_file_proto\": r\"file://\", \"has_http_proto\": r\"http://\",\n",
    "    \"has_https_proto\": r\"https://\",\n",
    "}\n",
    "for name, pattern in attack_keywords.items():\n",
    "    df[name] = df[\"text\"].str.contains(pattern, case=False, regex=True, na=False).astype(int)\n",
    "\n",
    "# === Step 5: Entropy & Ratio Features ===\n",
    "def entropy(s):\n",
    "    if not s or len(s) == 0:\n",
    "        return 0\n",
    "    p = [s.count(c)/len(s) for c in set(s)]\n",
    "    return -sum(x*np.log2(x) for x in p)\n",
    "\n",
    "df[\"url_entropy\"] = df[\"URL\"].fillna(\"\").apply(entropy)\n",
    "df[\"content_entropy\"] = df[\"content\"].fillna(\"\").apply(entropy)\n",
    "df[\"digit_ratio\"] = df[\"content\"].fillna(\"\").apply(lambda x: sum(c.isdigit() for c in str(x)) / (len(str(x)) + 1))\n",
    "df[\"symbol_ratio\"] = df[\"content\"].fillna(\"\").apply(lambda x: sum(not c.isalnum() for c in str(x)) / (len(str(x)) + 1))\n",
    "\n",
    "# === Step 6: Define Column Groups ===\n",
    "text_col = \"text\"\n",
    "cat_cols = [\"Method\", \"connection\", \"content-type\"]\n",
    "num_cols = [\n",
    "    \"url_len\", \"content_len\", \"num_params\", \"cookie_len\",\n",
    "    \"url_entropy\", \"content_entropy\", \"digit_ratio\", \"symbol_ratio\"\n",
    "] + [f\"count_{ch}\" for ch in bad_chars] + list(attack_keywords.keys())\n",
    "\n",
    "# === Step 7: Build Column Transformer ===\n",
    "tfidf = TfidfVectorizer(analyzer=\"char\", ngram_range=(3,5), max_features=3000)\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"text\", tfidf, text_col),\n",
    "    (\"cat\", ohe, cat_cols),\n",
    "    (\"num\", \"passthrough\", num_cols)\n",
    "])\n",
    "\n",
    "# === Step 8: Fit and Transform ===\n",
    "preprocess.fit(df)\n",
    "X = preprocess.transform(df)\n",
    "X_dense = X.toarray() if sp.issparse(X) else X\n",
    "feature_names = preprocess.get_feature_names_out()\n",
    "\n",
    "# === Step 9: Save to CSV ===\n",
    "features_df = pd.DataFrame(X_dense, columns=feature_names)\n",
    "if \"classification\" in df.columns:\n",
    "    features_df[\"target\"] = df[\"classification\"]\n",
    "\n",
    "features_df.to_csv(\"FeatureSet.csv\", index=False)\n",
    "\n",
    "# === Step 10: Print Summary ===\n",
    "print(\"✅ Feature engineering complete and saved as FeatureSet.csv\")\n",
    "print(\"  - TF-IDF features:\", len(preprocess.named_transformers_[\"text\"].vocabulary_))\n",
    "print(\"  - One-hot categorical features:\", sum(len(c) for c in preprocess.named_transformers_[\"cat\"].categories_))\n",
    "print(\"  - Numeric + heuristic features:\", len(num_cols))\n",
    "print(\"  - TOTAL features:\", X_dense.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54388533-02bb-425c-80db-9d1cee190ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"FeatureSet.csv\")\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "385144eb-1cc6-4807-879b-da3fda11632e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 36000 samples\n",
      "Class 1: 25065 samples\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"Class {label}: {count} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d4b6f1e-99bb-4b31-9ec9-b8c01ac549a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Balanced using SMOTETomek\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import scipy.sparse as sp\n",
    "\n",
    "try:\n",
    "    # SMOTETomek prefers dense inputs\n",
    "    X_array = X.to_numpy().astype(\"float32\")\n",
    "    smt = SMOTETomek(random_state=42)\n",
    "    X_bal, y_bal = smt.fit_resample(X_array, y)\n",
    "    print(\"✅ Balanced using SMOTETomek\")\n",
    "except:\n",
    "    # Fallback: Random undersampling\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_bal, y_bal = rus.fit_resample(X, y)\n",
    "    print(\"⚠️ SMOTETomek failed. Used RandomUnderSampler instead.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4782326a-2175-40a3-9221-5910b8e16441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved balanced dataset as BalancedDataset.csv\n"
     ]
    }
   ],
   "source": [
    "balanced_df = pd.DataFrame(X_bal, columns=X.columns)\n",
    "balanced_df[\"target\"] = y_bal\n",
    "\n",
    "balanced_df.to_csv(\"BalancedDataset.csv\", index=False)\n",
    "print(\"✅ Saved balanced dataset as BalancedDataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57790206-f8e7-44ac-b3a5-37d1376d068b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after balancing:\n",
      "Class 0: 35526 samples\n",
      "Class 1: 35526 samples\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_bal, return_counts=True)\n",
    "print(\"Class distribution after balancing:\")\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"Class {label}: {count} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5c5385c-aa39-4a86-ad9c-9f51f3f84752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"BalancedDataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55d2bdd6-9a66-4dba-862a-2e8fc53005cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/16] params={'n_estimators': 300, 'max_depth': 12, 'min_samples_leaf': 1, 'min_samples_split': 2, 'max_features': 'sqrt'}  val F1_w=0.9286\n",
      "[02/16] params={'n_estimators': 300, 'max_depth': 12, 'min_samples_leaf': 1, 'min_samples_split': 10, 'max_features': 'sqrt'}  val F1_w=0.9300\n",
      "[03/16] params={'n_estimators': 300, 'max_depth': 12, 'min_samples_leaf': 4, 'min_samples_split': 2, 'max_features': 'sqrt'}  val F1_w=0.9211\n",
      "[04/16] params={'n_estimators': 300, 'max_depth': 12, 'min_samples_leaf': 4, 'min_samples_split': 10, 'max_features': 'sqrt'}  val F1_w=0.9245\n",
      "[05/16] params={'n_estimators': 300, 'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 2, 'max_features': 'sqrt'}  val F1_w=0.9460\n",
      "[06/16] params={'n_estimators': 300, 'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 10, 'max_features': 'sqrt'}  val F1_w=0.9458\n",
      "[07/16] params={'n_estimators': 300, 'max_depth': 18, 'min_samples_leaf': 4, 'min_samples_split': 2, 'max_features': 'sqrt'}  val F1_w=0.9430\n",
      "[08/16] params={'n_estimators': 300, 'max_depth': 18, 'min_samples_leaf': 4, 'min_samples_split': 10, 'max_features': 'sqrt'}  val F1_w=0.9440\n",
      "[09/16] params={'n_estimators': 500, 'max_depth': 12, 'min_samples_leaf': 1, 'min_samples_split': 2, 'max_features': 'sqrt'}  val F1_w=0.9291\n",
      "[10/16] params={'n_estimators': 500, 'max_depth': 12, 'min_samples_leaf': 1, 'min_samples_split': 10, 'max_features': 'sqrt'}  val F1_w=0.9274\n",
      "[11/16] params={'n_estimators': 500, 'max_depth': 12, 'min_samples_leaf': 4, 'min_samples_split': 2, 'max_features': 'sqrt'}  val F1_w=0.9188\n",
      "[12/16] params={'n_estimators': 500, 'max_depth': 12, 'min_samples_leaf': 4, 'min_samples_split': 10, 'max_features': 'sqrt'}  val F1_w=0.9260\n",
      "[13/16] params={'n_estimators': 500, 'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 2, 'max_features': 'sqrt'}  val F1_w=0.9464\n",
      "[14/16] params={'n_estimators': 500, 'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 10, 'max_features': 'sqrt'}  val F1_w=0.9457\n",
      "[15/16] params={'n_estimators': 500, 'max_depth': 18, 'min_samples_leaf': 4, 'min_samples_split': 2, 'max_features': 'sqrt'}  val F1_w=0.9433\n",
      "[16/16] params={'n_estimators': 500, 'max_depth': 18, 'min_samples_leaf': 4, 'min_samples_split': 10, 'max_features': 'sqrt'}  val F1_w=0.9441\n",
      "\n",
      "Best validation F1 (weighted): 0.9464\n",
      "Best params: {'n_estimators': 500, 'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 2, 'max_features': 'sqrt'}\n",
      "\n",
      "=== Test Performance ===\n",
      "Accuracy: 0.9412\n",
      "F1 (weighted): 0.9410\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94      7106\n",
      "           1       0.90      0.99      0.94      7105\n",
      "\n",
      "    accuracy                           0.94     14211\n",
      "   macro avg       0.95      0.94      0.94     14211\n",
      "weighted avg       0.95      0.94      0.94     14211\n",
      "\n",
      "Confusion matrix:\n",
      "[[6328  778]\n",
      " [  58 7047]]\n",
      "ROC-AUC: 0.9979\n",
      "✅ Saved model as rf_waf_model_94.pkl\n",
      "✅ Saved preprocessor as preprocess.pkl\n"
     ]
    }
   ],
   "source": [
    "# Lightweight Random Forest tuning (resource-friendly)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import gc\n",
    "\n",
    "# 0) Load data\n",
    "df = pd.read_csv(\"BalancedDataset.csv\")   # change to .csv if needed\n",
    "TARGET_COL = \"target\"  # <-- set your label column\n",
    "\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "# Identify column types\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "# Preprocess\n",
    "numeric_preprocess = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))])\n",
    "categorical_preprocess = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", numeric_preprocess, num_cols),\n",
    "    (\"cat\", categorical_preprocess, cat_cols),\n",
    "])\n",
    "\n",
    "# Split once into train+test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# From the train, carve out a small validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, stratify=y_train_full, random_state=42\n",
    ")\n",
    "\n",
    "def make_pipe(params):\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=params[\"n_estimators\"],\n",
    "        max_depth=params[\"max_depth\"],\n",
    "        min_samples_split=params[\"min_samples_split\"],\n",
    "        min_samples_leaf=params[\"min_samples_leaf\"],\n",
    "        max_features=params[\"max_features\"],\n",
    "        bootstrap=True,\n",
    "        random_state=42,\n",
    "        n_jobs=2  # keep things cool; use -1 if you want max speed\n",
    "    )\n",
    "    return Pipeline([(\"prep\", preprocess), (\"rf\", rf)])\n",
    "\n",
    "# Tiny, sensible grid (16 combos total)\n",
    "grid = []\n",
    "for n in [300, 500]:\n",
    "    for d in [12, 18]:\n",
    "        for msl in [1, 4]:\n",
    "            for mss in [2, 10]:\n",
    "                grid.append({\n",
    "                    \"n_estimators\": n,\n",
    "                    \"max_depth\": d,\n",
    "                    \"min_samples_leaf\": msl,\n",
    "                    \"min_samples_split\": mss,\n",
    "                    \"max_features\": \"sqrt\",\n",
    "                })\n",
    "\n",
    "best_score = -1.0\n",
    "best_params = None\n",
    "\n",
    "for i, params in enumerate(grid, 1):\n",
    "    pipe = make_pipe(params)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred_val = pipe.predict(X_val)\n",
    "    f1w = f1_score(y_val, y_pred_val, average=\"weighted\")\n",
    "    # keep memory tidy\n",
    "    del pipe\n",
    "    gc.collect()\n",
    "    print(f\"[{i:02d}/{len(grid)}] params={params}  val F1_w={f1w:.4f}\")\n",
    "    if f1w > best_score:\n",
    "        best_score = f1w\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest validation F1 (weighted):\", round(best_score, 4))\n",
    "print(\"Best params:\", best_params)\n",
    "\n",
    "# Retrain best on full training data\n",
    "best_pipe = make_pipe(best_params)\n",
    "best_pipe.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Evaluate on HOLD-OUT test\n",
    "y_pred = best_pipe.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1w = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "print(\"\\n=== Test Performance ===\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"F1 (weighted): {f1w:.4f}\")\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Optional: ROC-AUC\n",
    "try:\n",
    "    y_proba = best_pipe.predict_proba(X_test)\n",
    "    if len(np.unique(y)) == 2:\n",
    "        auc = roc_auc_score(y_test, y_proba[:, 1])\n",
    "    else:\n",
    "        auc = roc_auc_score(y_test, y_proba, multi_class=\"ovr\")\n",
    "    print(f\"ROC-AUC: {auc:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"ROC-AUC not computed: {e}\")\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(best_pipe, \"rf_waf_model_94.pkl\")\n",
    "print(\"✅ Saved model as rf_waf_model_94.pkl\")\n",
    "\n",
    "joblib.dump(preprocess, \"preprocess.pkl\")\n",
    "print(\"✅ Saved preprocessor as preprocess.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75184e8e-0f96-4ef6-b8aa-2df1814d0025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumitkashania/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/3] params={'C': 0.1, 'penalty': 'l2'}  val F1_w=0.9151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumitkashania/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/3] params={'C': 1.0, 'penalty': 'l2'}  val F1_w=0.9099\n",
      "[03/3] params={'C': 10.0, 'penalty': 'l2'}  val F1_w=0.9052\n",
      "\n",
      "Best validation F1 (weighted): 0.9151\n",
      "Best params (LR): {'C': 0.1, 'penalty': 'l2'}\n",
      "\n",
      "=== Logistic Regression Test Performance ===\n",
      "Accuracy: 0.9048\n",
      "F1 (weighted): 0.9048\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90      7106\n",
      "           1       0.90      0.91      0.91      7105\n",
      "\n",
      "    accuracy                           0.90     14211\n",
      "   macro avg       0.90      0.90      0.90     14211\n",
      "weighted avg       0.90      0.90      0.90     14211\n",
      "\n",
      "Confusion matrix:\n",
      "[[6370  736]\n",
      " [ 617 6488]]\n",
      "✅ Saved model as lr_waf_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Logistic Regression Model\n",
    "# =========================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def make_pipe_lr(params):\n",
    "    lr = LogisticRegression(\n",
    "        C=params[\"C\"],\n",
    "        penalty=params[\"penalty\"],\n",
    "        solver=\"lbfgs\",   # works with L2 penalty\n",
    "        max_iter=500,\n",
    "        random_state=42,\n",
    "        n_jobs=2\n",
    "    )\n",
    "    return Pipeline([(\"prep\", preprocess), (\"lr\", lr)])\n",
    "\n",
    "# Simple hyperparameter grid\n",
    "grid_lr = []\n",
    "for C in [0.1, 1.0, 10.0]:\n",
    "    for penalty in [\"l2\"]:  # l1 needs liblinear/saga; keep it simple\n",
    "        grid_lr.append({\"C\": C, \"penalty\": penalty})\n",
    "\n",
    "best_score_lr = -1.0\n",
    "best_params_lr = None\n",
    "\n",
    "for i, params in enumerate(grid_lr, 1):\n",
    "    pipe = make_pipe_lr(params)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred_val = pipe.predict(X_val)\n",
    "    f1w = f1_score(y_val, y_pred_val, average=\"weighted\")\n",
    "    print(f\"[{i:02d}/{len(grid_lr)}] params={params}  val F1_w={f1w:.4f}\")\n",
    "    if f1w > best_score_lr:\n",
    "        best_score_lr = f1w\n",
    "        best_params_lr = params\n",
    "\n",
    "print(\"\\nBest validation F1 (weighted):\", round(best_score_lr, 4))\n",
    "print(\"Best params (LR):\", best_params_lr)\n",
    "\n",
    "# Retrain best on full training data\n",
    "best_pipe_lr = make_pipe_lr(best_params_lr)\n",
    "best_pipe_lr.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Evaluate on test\n",
    "y_pred = best_pipe_lr.predict(X_test)\n",
    "print(\"\\n=== Logistic Regression Test Performance ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1 (weighted): {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Save\n",
    "joblib.dump(best_pipe_lr, \"lr_waf_model.pkl\")\n",
    "print(\"✅ Saved model as lr_waf_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8d30a9-cbba-4e9f-b686-a39067dffce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1714e-dd93-4a8d-9005-555333114f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d880ef98-8dfd-492b-9329-1d8b7818ccd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/3] params={'max_depth': 12, 'min_samples_split': 20, 'min_samples_leaf': 10}  val F1_w=0.8886\n",
      "[02/3] params={'max_depth': 15, 'min_samples_split': 20, 'min_samples_leaf': 10}  val F1_w=0.9124\n",
      "[03/3] params={'max_depth': 18, 'min_samples_split': 30, 'min_samples_leaf': 15}  val F1_w=0.9262\n",
      "\n",
      "Best validation F1 (weighted): 0.9262\n",
      "Best params (DT): {'max_depth': 18, 'min_samples_split': 30, 'min_samples_leaf': 15}\n",
      "\n",
      "=== Decision Tree Test Performance ===\n",
      "Accuracy: 0.9324\n",
      "F1 (weighted): 0.9341\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89      1634\n",
      "           1       0.99      0.91      0.95      4338\n",
      "\n",
      "    accuracy                           0.93      5972\n",
      "   macro avg       0.90      0.95      0.92      5972\n",
      "weighted avg       0.94      0.93      0.93      5972\n",
      "\n",
      "Confusion matrix:\n",
      "[[1599   35]\n",
      " [ 369 3969]]\n",
      "ROC-AUC: 0.9764\n",
      "✅ Saved model as dt_waf_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Decision Tree Model (robust)\n",
    "# =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# ---- Load & basic hygiene ----\n",
    "df = pd.read_csv(\"BalancedDataset.csv\")\n",
    "TARGET_COL = \"target\"\n",
    "\n",
    "# 1) Drop exact duplicates (prevents train/test clones)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# 2) OPTIONAL: choose a grouping key if present to avoid leakage\n",
    "#    Add more candidates if your schema differs.\n",
    "GROUP_CANDIDATES = [\"client_ip\", \"session_id\", \"src_ip\", \"user\"]\n",
    "group_col = next((c for c in GROUP_CANDIDATES if c in df.columns), None)\n",
    "\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "# Column types\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "# Preprocessing\n",
    "numeric_preprocess = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))])\n",
    "categorical_preprocess = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", numeric_preprocess, num_cols),\n",
    "    (\"cat\", categorical_preprocess, cat_cols),\n",
    "])\n",
    "\n",
    "# ---- Split: group-aware if possible ----\n",
    "if group_col is not None:\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    groups = df[group_col]\n",
    "    train_idx, test_idx = next(gss.split(X, y, groups))\n",
    "    X_train_full, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train_full, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "else:\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "# Small validation split from the train\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, stratify=y_train_full, random_state=42\n",
    ")\n",
    "\n",
    "def make_pipe_dt(params):\n",
    "    dt = DecisionTreeClassifier(\n",
    "        max_depth=params[\"max_depth\"],\n",
    "        min_samples_split=params[\"min_samples_split\"],\n",
    "        min_samples_leaf=params[\"min_samples_leaf\"],\n",
    "        random_state=42\n",
    "    )\n",
    "    return Pipeline([(\"prep\", preprocess), (\"dt\", dt)])\n",
    "\n",
    "# Strong regularization grid (prevents overfit)\n",
    "grid_dt = [\n",
    "    {\"max_depth\": 12, \"min_samples_split\": 20, \"min_samples_leaf\": 10},\n",
    "    {\"max_depth\": 15, \"min_samples_split\": 20, \"min_samples_leaf\": 10},\n",
    "    {\"max_depth\": 18, \"min_samples_split\": 30, \"min_samples_leaf\": 15},\n",
    "]\n",
    "\n",
    "best_score_dt = -1.0\n",
    "best_params_dt = None\n",
    "\n",
    "for i, params in enumerate(grid_dt, 1):\n",
    "    pipe = make_pipe_dt(params)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred_val = pipe.predict(X_val)\n",
    "    f1w = f1_score(y_val, y_pred_val, average=\"weighted\")\n",
    "    print(f\"[{i:02d}/{len(grid_dt)}] params={params}  val F1_w={f1w:.4f}\")\n",
    "    if f1w > best_score_dt:\n",
    "        best_score_dt = f1w\n",
    "        best_params_dt = params\n",
    "\n",
    "print(\"\\nBest validation F1 (weighted):\", round(best_score_dt, 4))\n",
    "print(\"Best params (DT):\", best_params_dt)\n",
    "\n",
    "# Retrain best on full training data\n",
    "best_pipe_dt = make_pipe_dt(best_params_dt)\n",
    "best_pipe_dt.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Evaluate on test\n",
    "y_pred = best_pipe_dt.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1w = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "print(\"\\n=== Decision Tree Test Performance ===\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"F1 (weighted): {f1w:.4f}\")\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Optional: ROC-AUC\n",
    "try:\n",
    "    proba = best_pipe_dt.predict_proba(X_test)\n",
    "    if len(np.unique(y)) == 2:\n",
    "        auc = roc_auc_score(y_test, proba[:, 1])\n",
    "    else:\n",
    "        auc = roc_auc_score(y_test, proba, multi_class=\"ovr\")\n",
    "    print(f\"ROC-AUC: {auc:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"ROC-AUC not computed: {e}\")\n",
    "\n",
    "joblib.dump(best_pipe_dt, \"dt_waf_model.pkl\")\n",
    "print(\"✅ Saved model as dt_waf_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea4a777e-3903-40c3-b26d-f8a35a894e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression (aim ~90%) ===\n",
      "Accuracy: 0.9382\n",
      "F1 (weighted): 0.9379\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89      1634\n",
      "           1       0.95      0.96      0.96      4338\n",
      "\n",
      "    accuracy                           0.94      5972\n",
      "   macro avg       0.93      0.92      0.92      5972\n",
      "weighted avg       0.94      0.94      0.94      5972\n",
      "\n",
      "Confusion matrix:\n",
      "[[1421  213]\n",
      " [ 156 4182]]\n",
      "✅ Saved: lr_waf_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Logistic Regression \n",
    "# ============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "REG_C = 0.001          # smaller => lower accuracy (try 0.0005 if still high)\n",
    "OHE_MIN_FREQ = 0.5     # as a fraction (10%); raise to 0.20 if still high\n",
    "USE_NUMERICS_ONLY = False  # set True if you want to drop categoricals entirely\n",
    "\n",
    "CSV_PATH = \"BalancedDataset.csv\"\n",
    "TARGET_COL = \"target\"\n",
    "\n",
    "# Likely leaky / super-high-cardinality columns to drop if present\n",
    "DROP_COLS = [\n",
    "    \"label\",\"is_attack\",\"blocked\",\"waf_action\",\"anomaly_score\",\n",
    "    \"alert\",\"matched_rule\",\"rule_id\",\"decision\",\"ground_truth\",\n",
    "    \"uri\",\"url\",\"path\",\"request_uri\",\"query\",\"args\",\"cookies\",\n",
    "    \"user_agent\",\"referrer\",\"raw\",\"request_body\",\"headers\",\"message\"\n",
    "]\n",
    "\n",
    "# Optional grouping to avoid leakage (use any that exist)\n",
    "GROUP_KEYS = [\"timestamp\", \"client_ip\", \"session_id\", \"src_ip\", \"user\", \"uid\"]\n",
    "\n",
    "# ----------------- Load & clean -----------------\n",
    "df = pd.read_csv(CSV_PATH).drop_duplicates()\n",
    "\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise ValueError(f\"'{TARGET_COL}' not found. Got: {list(df.columns)[:12]}...\")\n",
    "\n",
    "to_drop = [c for c in DROP_COLS if c in df.columns and c != TARGET_COL]\n",
    "if to_drop:\n",
    "    df = df.drop(columns=to_drop)\n",
    "\n",
    "# Prefer time-based split if 'timestamp' exists and is parseable\n",
    "time_split_done = False\n",
    "if \"timestamp\" in df.columns:\n",
    "    try:\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
    "        df = df.sort_values(\"timestamp\")\n",
    "        cut = int(len(df) * 0.8)\n",
    "        train_df, test_df = df.iloc[:cut], df.iloc[cut:]\n",
    "        X_train_full = train_df.drop(columns=[TARGET_COL])\n",
    "        y_train_full = train_df[TARGET_COL]\n",
    "        X_test = test_df.drop(columns=[TARGET_COL])\n",
    "        y_test = test_df[TARGET_COL]\n",
    "        time_split_done = True\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# If not time split, do group-aware if any key exists; else stratified\n",
    "if not time_split_done:\n",
    "    X = df.drop(columns=[TARGET_COL])\n",
    "    y = df[TARGET_COL]\n",
    "    group_col = next((k for k in GROUP_KEYS if k in df.columns and k != TARGET_COL), None)\n",
    "    if group_col is not None:\n",
    "        gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "        groups = df[group_col]\n",
    "        train_idx, test_idx = next(gss.split(X, y, groups))\n",
    "        X_train_full, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train_full, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    else:\n",
    "        X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, stratify=y, random_state=42\n",
    "        )\n",
    "\n",
    "# ----------------- Columns -----------------\n",
    "num_cols = X_train_full.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = [] if USE_NUMERICS_ONLY else X_train_full.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "# ----------------- Preprocess -----------------\n",
    "numeric_prep = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler(with_mean=False))   # LR likes scaled numerics; keeps sparse OK\n",
    "])\n",
    "\n",
    "# Collapse rare categories; if older sklearn, fallback without min_frequency\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", min_frequency=OHE_MIN_FREQ)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "categorical_prep = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", ohe)\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", numeric_prep, num_cols),\n",
    "    (\"cat\", categorical_prep, cat_cols),\n",
    "], remainder=\"drop\")\n",
    "\n",
    "# ----------------- Model -----------------\n",
    "clf = LogisticRegression(\n",
    "    C=REG_C,          # main knob\n",
    "    penalty=\"l2\",\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"clf\", clf)\n",
    "])\n",
    "\n",
    "# ----------------- Train & Eval -----------------\n",
    "pipe.fit(X_train_full, y_train_full)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1w = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "print(\"\\n=== Logistic Regression ===\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"F1 (weighted): {f1w:.4f}\")\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "joblib.dump(pipe, \"lr_waf_model.pkl\")\n",
    "print(\"✅ Saved: lr_waf_model.pkl\")\n",
    "\n",
    "# ---- If it's still above ~92% ----\n",
    "# 1) Decrease REG_C further (e.g., 0.0005 or 0.0002)\n",
    "# 2) Increase OHE_MIN_FREQ (e.g., 0.20 or 0.30)\n",
    "# 3) Set USE_NUMERICS_ONLY = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e18793f6-9461-41a2-bd6e-020d7fbbec4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/3] params={'C': 0.1, 'penalty': 'l2'}  val F1_w=0.9479\n",
      "[02/3] params={'C': 1.0, 'penalty': 'l2'}  val F1_w=0.9483\n",
      "[03/3] params={'C': 10.0, 'penalty': 'l2'}  val F1_w=0.9483\n",
      "\n",
      "Best validation F1 (weighted): 0.9483\n",
      "Best params (LR): {'C': 1.0, 'penalty': 'l2'}\n",
      "\n",
      "=== Logistic Regression Test Performance ===\n",
      "Accuracy: 0.9605\n",
      "F1 (weighted): 0.9605\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1634\n",
      "           1       0.97      0.97      0.97      4338\n",
      "\n",
      "    accuracy                           0.96      5972\n",
      "   macro avg       0.95      0.95      0.95      5972\n",
      "weighted avg       0.96      0.96      0.96      5972\n",
      "\n",
      "Confusion matrix:\n",
      "[[1514  120]\n",
      " [ 116 4222]]\n",
      "✅ Saved model as lr_waf_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Logistic Regression Model (no warnings)\n",
    "# =========================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "# (Optional) if you want to silence any remaining convergence warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "def make_pipe_lr(params):\n",
    "    lr = LogisticRegression(\n",
    "        C=params[\"C\"],\n",
    "        penalty=params[\"penalty\"],  # 'l2'\n",
    "        solver=\"saga\",              # better for high-dim sparse (OHE) than lbfgs\n",
    "        max_iter=2000,              # more iterations so it actually converges\n",
    "        tol=1e-3,                   # slightly looser tolerance helps convergence\n",
    "        random_state=42\n",
    "    )\n",
    "    # NOTE: reuse your existing 'preprocess' from above\n",
    "    return Pipeline([(\"prep\", preprocess), (\"lr\", lr)])\n",
    "\n",
    "# Keep your tiny grid (you can also try smaller C if you want stronger regularization)\n",
    "grid_lr = [{\"C\": 0.1, \"penalty\": \"l2\"},\n",
    "           {\"C\": 1.0, \"penalty\": \"l2\"},\n",
    "           {\"C\": 10.0, \"penalty\": \"l2\"}]\n",
    "\n",
    "best_score_lr = -1.0\n",
    "best_params_lr = None\n",
    "\n",
    "for i, params in enumerate(grid_lr, 1):\n",
    "    pipe = make_pipe_lr(params)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred_val = pipe.predict(X_val)\n",
    "    f1w = f1_score(y_val, y_pred_val, average=\"weighted\")\n",
    "    print(f\"[{i:02d}/{len(grid_lr)}] params={params}  val F1_w={f1w:.4f}\")\n",
    "    if f1w > best_score_lr:\n",
    "        best_score_lr = f1w\n",
    "        best_params_lr = params\n",
    "\n",
    "print(\"\\nBest validation F1 (weighted):\", round(best_score_lr, 4))\n",
    "print(\"Best params (LR):\", best_params_lr)\n",
    "\n",
    "# Retrain best on full training data\n",
    "best_pipe_lr = make_pipe_lr(best_params_lr)\n",
    "best_pipe_lr.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Evaluate on test\n",
    "y_pred = best_pipe_lr.predict(X_test)\n",
    "print(\"\\n=== Logistic Regression Test Performance ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1 (weighted): {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Save\n",
    "joblib.dump(best_pipe_lr, \"lr_waf_model.pkl\")\n",
    "print(\"✅ Saved model as lr_waf_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c61fde29-41b7-446c-83cf-5a38fc2690eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/3] params={'C': 0.001}  val F1_w=0.9315\n",
      "[02/3] params={'C': 0.002}  val F1_w=0.9362\n",
      "[03/3] params={'C': 0.005}  val F1_w=0.9451\n",
      "\n",
      "Best validation F1 (weighted): 0.9451\n",
      "Best params (LR): {'C': 0.005}\n",
      "\n",
      "=== Logistic Regression Test Performance (~90% target) ===\n",
      "Accuracy: 0.9489\n",
      "F1 (weighted): 0.9489\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91      1634\n",
      "           1       0.96      0.97      0.96      4338\n",
      "\n",
      "    accuracy                           0.95      5972\n",
      "   macro avg       0.94      0.93      0.94      5972\n",
      "weighted avg       0.95      0.95      0.95      5972\n",
      "\n",
      "Confusion matrix:\n",
      "[[1475  159]\n",
      " [ 146 4192]]\n",
      "✅ Saved model as lr_waf_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Logistic Regression tuned ~90%\n",
    "# =========================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def make_pipe_lr(params):\n",
    "    # Build a *stricter* preprocessor just for LR:\n",
    "    # - scale numerics\n",
    "    # - collapse rare categories so the model can't memorize tails\n",
    "    numeric_prep = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),\n",
    "    ])\n",
    "    try:\n",
    "        # Collapse categories that appear in <20% of rows (aggressive)\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\", min_frequency=0.20)\n",
    "    except TypeError:\n",
    "        # Fallback if your sklearn doesn't support min_frequency\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    categorical_prep = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ohe\", ohe),\n",
    "    ])\n",
    "    preprocess_lr = ColumnTransformer([\n",
    "        (\"num\", numeric_prep, num_cols),\n",
    "        (\"cat\", categorical_prep, cat_cols),\n",
    "    ], remainder=\"drop\")\n",
    "\n",
    "    lr = LogisticRegression(\n",
    "        C=params[\"C\"],          # very small C => strong regularization\n",
    "        penalty=\"l2\",\n",
    "        solver=\"saga\",          # good for sparse, high-dim features\n",
    "        max_iter=2000,\n",
    "        tol=1e-3,\n",
    "        random_state=42\n",
    "    )\n",
    "    return Pipeline([(\"prep\", preprocess_lr), (\"lr\", lr)])\n",
    "\n",
    "# MUCH smaller Cs to pull accuracy down toward ~90%\n",
    "grid_lr = [\n",
    "    {\"C\": 0.001},\n",
    "    {\"C\": 0.002},\n",
    "    {\"C\": 0.005},\n",
    "]\n",
    "\n",
    "best_score_lr = -1.0\n",
    "best_params_lr = None\n",
    "\n",
    "for i, params in enumerate(grid_lr, 1):\n",
    "    pipe = make_pipe_lr(params)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred_val = pipe.predict(X_val)\n",
    "    f1w = f1_score(y_val, y_pred_val, average=\"weighted\")\n",
    "    print(f\"[{i:02d}/{len(grid_lr)}] params={params}  val F1_w={f1w:.4f}\")\n",
    "    if f1w > best_score_lr:\n",
    "        best_score_lr = f1w\n",
    "        best_params_lr = params\n",
    "\n",
    "print(\"\\nBest validation F1 (weighted):\", round(best_score_lr, 4))\n",
    "print(\"Best params (LR):\", best_params_lr)\n",
    "\n",
    "# Retrain best on full training data\n",
    "best_pipe_lr = make_pipe_lr(best_params_lr)\n",
    "best_pipe_lr.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Evaluate on test\n",
    "y_pred = best_pipe_lr.predict(X_test)\n",
    "print(\"\\n=== Logistic Regression Test Performance (~90% target) ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1 (weighted): {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Save\n",
    "joblib.dump(best_pipe_lr, \"lr_waf_model.pkl\")\n",
    "print(\"✅ Saved model as lr_waf_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32846398-976c-4146-977c-013874902701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression Test Performance (~90% target) ===\n",
      "Accuracy: 0.9193\n",
      "F1 (weighted): 0.9178\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.80      0.84      1634\n",
      "           1       0.93      0.96      0.95      4338\n",
      "\n",
      "    accuracy                           0.92      5972\n",
      "   macro avg       0.91      0.88      0.89      5972\n",
      "weighted avg       0.92      0.92      0.92      5972\n",
      "\n",
      "Confusion matrix:\n",
      "[[1304  330]\n",
      " [ 152 4186]]\n",
      "✅ Saved model as lr_waf_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Logistic Regression tuned to ~90% accuracy (drop-in)\n",
    "# =========================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# --- knobs ---\n",
    "C_GRID = [1e-4, 3e-4, 1e-3]   # very strong regularization -> lower accuracy\n",
    "\n",
    "def make_pipe_lr_numeric_only(C_value):\n",
    "    # numeric-only preprocessing keeps it simple and reduces overfitting\n",
    "    numeric_prep = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())  # dense numerics -> normal scaler\n",
    "    ])\n",
    "    preprocess_lr = ColumnTransformer([\n",
    "        (\"num\", numeric_prep, num_cols),   # uses your existing num_cols\n",
    "    ], remainder=\"drop\")\n",
    "\n",
    "    lr = LogisticRegression(\n",
    "        C=C_value,\n",
    "        penalty=\"l2\",\n",
    "        solver=\"lbfgs\",    # great for dense numeric features\n",
    "        max_iter=2000,\n",
    "        tol=1e-3,\n",
    "        random_state=42\n",
    "    )\n",
    "    return Pipeline([(\"prep\", preprocess_lr), (\"lr\", lr)])\n",
    "\n",
    "# Pick the model whose *validation accuracy* is closest to 0.90\n",
    "target = 0.90\n",
    "chosen = None\n",
    "chosen_diff = float(\"inf\")\n",
    "chosen_stats = None\n",
    "\n",
    "for i, C in enumerate(C_GRID, 1):\n",
    "    pipe = make_pipe_lr_numeric_only(C)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    val_pred = pipe.predict(X_val)\n",
    "    val_acc = accuracy_score(y_val, val_pred)\n",
    "    val_f1  = f1_score(y_val, val_pred, average=\"weighted\")\n",
    "    diff = abs(val_acc - target)\n",
    "    #print(f\"[LR {i}/{len(C_GRID)}] C={C:.5f}  val Acc={val_acc:.4f}  val F1_w={val_f1:.4f}\")\n",
    "    if diff < chosen_diff:\n",
    "        chosen, chosen_diff, chosen_stats = pipe, diff, (C, val_acc, val_f1)\n",
    "\n",
    "#print(f\"\\nSelected C={chosen_stats[0]:.5f}  (val Acc={chosen_stats[1]:.4f}, val F1_w={chosen_stats[2]:.4f})\")\n",
    "\n",
    "# Retrain on full training split for stability\n",
    "best_pipe_lr = make_pipe_lr_numeric_only(chosen_stats[0])\n",
    "best_pipe_lr.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Evaluate on HOLD-OUT test\n",
    "y_pred = best_pipe_lr.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "test_f1  = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "print(\"\\n=== Logistic Regression Test Performance (~90% target) ===\")\n",
    "print(f\"Accuracy: {test_acc:.4f}\")\n",
    "print(f\"F1 (weighted): {test_f1:.4f}\")\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "import joblib\n",
    "joblib.dump(best_pipe_lr, \"lr_waf_model.pkl\")\n",
    "print(\"✅ Saved model as lr_waf_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b65a7c9b-5454-4ca4-ae99-a531c7c56511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected numeric: 3085 | categorical: 0\n",
      "Target type: binary; n_classes=2 -> [0 1]\n",
      "[01/16] params={'n_estimators': 300, 'max_depth': 12, 'min_samples_leaf': 1, 'min_samples_split': 2, 'max_features': 'sqrt'}  val F1_w=0.9286\n",
      "[02/16] params={'n_estimators': 300, 'max_depth': 12, 'min_samples_leaf': 1, 'min_samples_split': 10, 'max_features': 'sqrt'}  val F1_w=0.9300\n",
      "[03/16] params={'n_estimators': 300, 'max_depth': 12, 'min_samples_leaf': 4, 'min_samples_split': 2, 'max_features': 'sqrt'}  val F1_w=0.9211\n",
      "[04/16] params={'n_estimators': 300, 'max_depth': 12, 'min_samples_leaf': 4, 'min_samples_split': 10, 'max_features': 'sqrt'}  val F1_w=0.9245\n",
      "[05/16] params={'n_estimators': 300, 'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 2, 'max_features': 'sqrt'}  val F1_w=0.9460\n",
      "[06/16] params={'n_estimators': 300, 'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 10, 'max_features': 'sqrt'}  val F1_w=0.9458\n",
      "[07/16] params={'n_estimators': 300, 'max_depth': 18, 'min_samples_leaf': 4, 'min_samples_split': 2, 'max_features': 'sqrt'}  val F1_w=0.9430\n",
      "[08/16] params={'n_estimators': 300, 'max_depth': 18, 'min_samples_leaf': 4, 'min_samples_split': 10, 'max_features': 'sqrt'}  val F1_w=0.9440\n",
      "[09/16] params={'n_estimators': 500, 'max_depth': 12, 'min_samples_leaf': 1, 'min_samples_split': 2, 'max_features': 'sqrt'}  val F1_w=0.9291\n",
      "[10/16] params={'n_estimators': 500, 'max_depth': 12, 'min_samples_leaf': 1, 'min_samples_split': 10, 'max_features': 'sqrt'}  val F1_w=0.9274\n",
      "[11/16] params={'n_estimators': 500, 'max_depth': 12, 'min_samples_leaf': 4, 'min_samples_split': 2, 'max_features': 'sqrt'}  val F1_w=0.9188\n",
      "[12/16] params={'n_estimators': 500, 'max_depth': 12, 'min_samples_leaf': 4, 'min_samples_split': 10, 'max_features': 'sqrt'}  val F1_w=0.9260\n",
      "[13/16] params={'n_estimators': 500, 'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 2, 'max_features': 'sqrt'}  val F1_w=0.9464\n",
      "[14/16] params={'n_estimators': 500, 'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 10, 'max_features': 'sqrt'}  val F1_w=0.9457\n",
      "[15/16] params={'n_estimators': 500, 'max_depth': 18, 'min_samples_leaf': 4, 'min_samples_split': 2, 'max_features': 'sqrt'}  val F1_w=0.9433\n",
      "[16/16] params={'n_estimators': 500, 'max_depth': 18, 'min_samples_leaf': 4, 'min_samples_split': 10, 'max_features': 'sqrt'}  val F1_w=0.9441\n",
      "\n",
      "Best validation F1 (weighted): 0.9464\n",
      "Best params: {'n_estimators': 500, 'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 2, 'max_features': 'sqrt'}\n",
      "\n",
      "=== Test Performance ===\n",
      "Accuracy: 0.9412\n",
      "F1 (weighted): 0.9410\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94      7106\n",
      "           1       0.90      0.99      0.94      7105\n",
      "\n",
      "    accuracy                           0.94     14211\n",
      "   macro avg       0.95      0.94      0.94     14211\n",
      "weighted avg       0.95      0.94      0.94     14211\n",
      "\n",
      "Confusion matrix:\n",
      "[[6328  778]\n",
      " [  58 7047]]\n",
      "ROC-AUC: 0.9979\n",
      "✅ Saved model as artifacts/rf_model.pkl\n",
      "✅ Saved preprocessor as artifacts/preprocess.pkl\n"
     ]
    }
   ],
   "source": [
    "# Lightweight Random Forest tuning (resource-friendly, data-adaptive)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "import gc, os, joblib, warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ========= EDIT ME =========\n",
    "CSV_PATH = \"BalancedDataset.csv\"   # <-- point to your data\n",
    "TARGET_COL = \"target\"              # <-- set to your label column name\n",
    "# ===========================\n",
    "\n",
    "# 0) Load data robustly\n",
    "read_kwargs = dict()\n",
    "if CSV_PATH.lower().endswith(\".csv\"):\n",
    "    # set these if your file needs them, e.g. read_kwargs.update({'sep': ';', 'encoding': 'utf-8'})\n",
    "    pass\n",
    "\n",
    "df = pd.read_csv(CSV_PATH, **read_kwargs)\n",
    "\n",
    "assert TARGET_COL in df.columns, f\"TARGET_COL='{TARGET_COL}' not found. Columns: {list(df.columns)}\"\n",
    "\n",
    "# Drop completely empty columns (saves memory / avoids OHE explosions)\n",
    "empty_cols = [c for c in df.columns if df[c].isna().all()]\n",
    "if empty_cols:\n",
    "    df = df.drop(columns=empty_cols)\n",
    "\n",
    "# Separate features/target\n",
    "y = df[TARGET_COL]\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "\n",
    "# Coerce obviously categorical string/object columns to 'category' dtype (lighter mem; faster OHE)\n",
    "for c in X.select_dtypes(include=[\"object\"]).columns:\n",
    "    # If it looks numeric but stored as object, try converting\n",
    "    try:\n",
    "        X[c] = pd.to_numeric(X[c])\n",
    "    except Exception:\n",
    "        X[c] = X[c].astype(\"category\")\n",
    "\n",
    "# Re-identify column types after coercion\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=[\"category\"]).columns.tolist()\n",
    "\n",
    "# Safety: handle case with no cat or no num cols\n",
    "print(f\"Detected numeric: {len(num_cols)} | categorical: {len(cat_cols)}\")\n",
    "\n",
    "# Preprocess\n",
    "numeric_preprocess = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "# OneHotEncoder notes:\n",
    "# - sparse_output=True keeps memory small (CSR matrix)\n",
    "# - dtype=float32 keeps RAM down\n",
    "# - min_frequency can cap rare categories into 'other' (good for very high-cardinality cat features)\n",
    "#   set min_frequency to 0.01 for 1% cutoff or an int like 10 for frequency >= 10\n",
    "categorical_preprocess = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\",\n",
    "                          sparse_output=True,  # sklearn >=1.2\n",
    "                          dtype=np.float32))\n",
    "    # If you have very wide categoricals, consider:\n",
    "    # (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True, dtype=np.float32, min_frequency=10))\n",
    "])\n",
    "\n",
    "# Build ColumnTransformer only with present types\n",
    "transformers = []\n",
    "if num_cols:\n",
    "    transformers.append((\"num\", numeric_preprocess, num_cols))\n",
    "if cat_cols:\n",
    "    transformers.append((\"cat\", categorical_preprocess, cat_cols))\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "preprocess = ColumnTransformer(transformers, remainder=\"drop\", n_jobs=None)\n",
    "\n",
    "# Check target type & class balance\n",
    "y_type = type_of_target(y)\n",
    "classes = np.unique(y.dropna())\n",
    "print(f\"Target type: {y_type}; n_classes={len(classes)} -> {classes[:8]}{'...' if len(classes)>8 else ''}\")\n",
    "\n",
    "# Stratify only if valid (>=2 classes and enough rows)\n",
    "stratify_vec = y if (len(classes) >= 2 and y.value_counts().min() >= 2) else None\n",
    "\n",
    "# Split once into train+test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=stratify_vec, random_state=42\n",
    ")\n",
    "\n",
    "# From the train, carve out a small validation set\n",
    "stratify_vec2 = y_train_full if (len(np.unique(y_train_full)) >= 2 and y_train_full.value_counts().min() >= 2) else None\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, stratify=stratify_vec2, random_state=42\n",
    ")\n",
    "\n",
    "# If your dataset is actually imbalanced, you can flip this to \"balanced\"\n",
    "USE_CLASS_WEIGHT_BALANCED = False\n",
    "\n",
    "def make_pipe(params):\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=params[\"n_estimators\"],\n",
    "        max_depth=params[\"max_depth\"],\n",
    "        min_samples_split=params[\"min_samples_split\"],\n",
    "        min_samples_leaf=params[\"min_samples_leaf\"],\n",
    "        max_features=params[\"max_features\"],\n",
    "        bootstrap=True,\n",
    "        # If imbalanced: set class_weight=\"balanced\"\n",
    "        class_weight=(\"balanced\" if USE_CLASS_WEIGHT_BALANCED else None),\n",
    "        # To save even more resources on very large data, consider subsampling each tree:\n",
    "        # max_samples=0.8,  # requires bootstrap=True; sklearn >=1.1\n",
    "        random_state=42,\n",
    "        n_jobs=2  # use -1 for max CPU; 2 keeps temps/RAM lower on laptops\n",
    "    )\n",
    "    return Pipeline([(\"prep\", preprocess), (\"rf\", rf)])\n",
    "\n",
    "# Tiny, sensible grid (feel free to adjust)\n",
    "grid = []\n",
    "for n in [300, 500]:\n",
    "    for d in [12, 18]:\n",
    "        for msl in [1, 4]:\n",
    "            for mss in [2, 10]:\n",
    "                grid.append({\n",
    "                    \"n_estimators\": n,\n",
    "                    \"max_depth\": d,\n",
    "                    \"min_samples_leaf\": msl,\n",
    "                    \"min_samples_split\": mss,\n",
    "                    \"max_features\": \"sqrt\",\n",
    "                })\n",
    "\n",
    "best_score = -1.0\n",
    "best_params = None\n",
    "\n",
    "for i, params in enumerate(grid, 1):\n",
    "    pipe = make_pipe(params)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred_val = pipe.predict(X_val)\n",
    "    f1w = f1_score(y_val, y_pred_val, average=\"weighted\")\n",
    "    del pipe\n",
    "    gc.collect()\n",
    "    print(f\"[{i:02d}/{len(grid)}] params={params}  val F1_w={f1w:.4f}\")\n",
    "    if f1w > best_score:\n",
    "        best_score = f1w\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest validation F1 (weighted):\", round(best_score, 4))\n",
    "print(\"Best params:\", best_params)\n",
    "\n",
    "# Retrain best on full training data\n",
    "best_pipe = make_pipe(best_params)\n",
    "best_pipe.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Evaluate on HOLD-OUT test\n",
    "y_pred = best_pipe.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1w = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "print(\"\\n=== Test Performance ===\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"F1 (weighted): {f1w:.4f}\")\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Optional: ROC-AUC (macro/ovr works for multiclass)\n",
    "try:\n",
    "    y_proba = best_pipe.predict_proba(X_test)\n",
    "    if len(np.unique(y)) == 2:\n",
    "        auc = roc_auc_score(y_test, y_proba[:, 1])\n",
    "    else:\n",
    "        auc = roc_auc_score(y_test, y_proba, multi_class=\"ovr\", average=\"macro\")\n",
    "    print(f\"ROC-AUC: {auc:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"ROC-AUC not computed: {e}\")\n",
    "\n",
    "# Persist artifacts\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "joblib.dump(best_pipe, \"artifacts/rf_model.pkl\")\n",
    "print(\"✅ Saved model as artifacts/rf_model.pkl\")\n",
    "\n",
    "# Optionally persist the fitted preprocessor alone (usually embedded in pipeline already)\n",
    "# If you want the preprocessor by itself trained on full data:\n",
    "fitted_prep = best_pipe.named_steps[\"prep\"]\n",
    "joblib.dump(fitted_prep, \"artifacts/preprocess.pkl\")\n",
    "print(\"✅ Saved preprocessor as artifacts/preprocess.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3947fe56-b1ea-4aa7-9023-585630596bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
